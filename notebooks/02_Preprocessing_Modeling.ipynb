{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab9e459",
   "metadata": {},
   "source": [
    "# Preprocessing Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e92933b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "486bb21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/startup data.csv'\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at '{file_path}'.\")\n",
    "    print(\"Please ensure you have downloaded 'startup_data.csv' from Kaggle and placed it in the same directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during loading: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c6295c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>state_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>id</th>\n",
       "      <th>city</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>...</th>\n",
       "      <th>object_id</th>\n",
       "      <th>has_VC</th>\n",
       "      <th>has_angel</th>\n",
       "      <th>has_roundA</th>\n",
       "      <th>has_roundB</th>\n",
       "      <th>has_roundC</th>\n",
       "      <th>has_roundD</th>\n",
       "      <th>avg_participants</th>\n",
       "      <th>is_top500</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005</td>\n",
       "      <td>CA</td>\n",
       "      <td>42.358880</td>\n",
       "      <td>-71.056820</td>\n",
       "      <td>92101</td>\n",
       "      <td>c:6669</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bandsintown</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>c:6669</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>acquired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>CA</td>\n",
       "      <td>37.238916</td>\n",
       "      <td>-121.973718</td>\n",
       "      <td>95032</td>\n",
       "      <td>c:16283</td>\n",
       "      <td>Los Gatos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TriCipher</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>c:16283</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>acquired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>CA</td>\n",
       "      <td>32.901049</td>\n",
       "      <td>-117.192656</td>\n",
       "      <td>92121</td>\n",
       "      <td>c:65620</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>San Diego CA 92121</td>\n",
       "      <td>Plixi</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>c:65620</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>acquired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>738</td>\n",
       "      <td>CA</td>\n",
       "      <td>37.320309</td>\n",
       "      <td>-122.050040</td>\n",
       "      <td>95014</td>\n",
       "      <td>c:42668</td>\n",
       "      <td>Cupertino</td>\n",
       "      <td>Cupertino CA 95014</td>\n",
       "      <td>Solidcore Systems</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>c:42668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>acquired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1002</td>\n",
       "      <td>CA</td>\n",
       "      <td>37.779281</td>\n",
       "      <td>-122.419236</td>\n",
       "      <td>94105</td>\n",
       "      <td>c:65806</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>San Francisco CA 94105</td>\n",
       "      <td>Inhale Digital</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>c:65806</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>352</td>\n",
       "      <td>CA</td>\n",
       "      <td>37.740594</td>\n",
       "      <td>-122.376471</td>\n",
       "      <td>94107</td>\n",
       "      <td>c:21343</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CoTweet</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>c:21343</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>acquired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>721</td>\n",
       "      <td>MA</td>\n",
       "      <td>42.504817</td>\n",
       "      <td>-71.195611</td>\n",
       "      <td>1803</td>\n",
       "      <td>c:41747</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>Burlington MA 1803</td>\n",
       "      <td>Reef Point Systems</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>c:41747</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>557</td>\n",
       "      <td>CA</td>\n",
       "      <td>37.408261</td>\n",
       "      <td>-122.015920</td>\n",
       "      <td>94089</td>\n",
       "      <td>c:31549</td>\n",
       "      <td>Sunnyvale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paracor Medical</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>c:31549</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>589</td>\n",
       "      <td>CA</td>\n",
       "      <td>37.556732</td>\n",
       "      <td>-122.288378</td>\n",
       "      <td>94404</td>\n",
       "      <td>c:33198</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Causata</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>c:33198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>acquired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>462</td>\n",
       "      <td>CA</td>\n",
       "      <td>37.386778</td>\n",
       "      <td>-121.966277</td>\n",
       "      <td>95054</td>\n",
       "      <td>c:26702</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>Santa Clara CA 95054</td>\n",
       "      <td>Asempra Technologies</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>c:26702</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>acquired</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>923 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 state_code   latitude   longitude zip_code       id  \\\n",
       "0          1005         CA  42.358880  -71.056820    92101   c:6669   \n",
       "1           204         CA  37.238916 -121.973718    95032  c:16283   \n",
       "2          1001         CA  32.901049 -117.192656    92121  c:65620   \n",
       "3           738         CA  37.320309 -122.050040    95014  c:42668   \n",
       "4          1002         CA  37.779281 -122.419236    94105  c:65806   \n",
       "..          ...        ...        ...         ...      ...      ...   \n",
       "918         352         CA  37.740594 -122.376471    94107  c:21343   \n",
       "919         721         MA  42.504817  -71.195611     1803  c:41747   \n",
       "920         557         CA  37.408261 -122.015920    94089  c:31549   \n",
       "921         589         CA  37.556732 -122.288378    94404  c:33198   \n",
       "922         462         CA  37.386778 -121.966277    95054  c:26702   \n",
       "\n",
       "              city              Unnamed: 6                  name  labels  ...  \\\n",
       "0        San Diego                     NaN           Bandsintown       1  ...   \n",
       "1        Los Gatos                     NaN             TriCipher       1  ...   \n",
       "2        San Diego      San Diego CA 92121                 Plixi       1  ...   \n",
       "3        Cupertino      Cupertino CA 95014     Solidcore Systems       1  ...   \n",
       "4    San Francisco  San Francisco CA 94105        Inhale Digital       0  ...   \n",
       "..             ...                     ...                   ...     ...  ...   \n",
       "918  San Francisco                     NaN               CoTweet       1  ...   \n",
       "919     Burlington      Burlington MA 1803    Reef Point Systems       0  ...   \n",
       "920      Sunnyvale                     NaN       Paracor Medical       0  ...   \n",
       "921  San Francisco                     NaN               Causata       1  ...   \n",
       "922    Santa Clara    Santa Clara CA 95054  Asempra Technologies       1  ...   \n",
       "\n",
       "    object_id has_VC has_angel has_roundA  has_roundB  has_roundC  has_roundD  \\\n",
       "0      c:6669      0         1          0           0           0           0   \n",
       "1     c:16283      1         0          0           1           1           1   \n",
       "2     c:65620      0         0          1           0           0           0   \n",
       "3     c:42668      0         0          0           1           1           1   \n",
       "4     c:65806      1         1          0           0           0           0   \n",
       "..        ...    ...       ...        ...         ...         ...         ...   \n",
       "918   c:21343      0         0          1           0           0           0   \n",
       "919   c:41747      1         0          0           1           0           0   \n",
       "920   c:31549      0         0          0           0           0           1   \n",
       "921   c:33198      0         0          1           1           0           0   \n",
       "922   c:26702      0         0          0           1           0           0   \n",
       "\n",
       "     avg_participants  is_top500    status  \n",
       "0              1.0000          0  acquired  \n",
       "1              4.7500          1  acquired  \n",
       "2              4.0000          1  acquired  \n",
       "3              3.3333          1  acquired  \n",
       "4              1.0000          1    closed  \n",
       "..                ...        ...       ...  \n",
       "918            6.0000          1  acquired  \n",
       "919            2.6667          1    closed  \n",
       "920            8.0000          1    closed  \n",
       "921            1.0000          1  acquired  \n",
       "922            3.0000          1  acquired  \n",
       "\n",
       "[923 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1749d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will test the models accuracy with minimal preprocessing\n",
    "# Dropping id columns and \n",
    "columns_to_drop = ['Unnamed: 0','id','Unnamed: 6','age_first_milestone_year',\n",
    "       'age_last_milestone_year', 'status', 'state_code.1', 'closed_at', ]\n",
    "df.drop(columns=columns_to_drop, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99b23e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state_code', 'latitude', 'longitude', 'zip_code', 'city', 'name',\n",
       "       'labels', 'founded_at', 'first_funding_at', 'last_funding_at',\n",
       "       'age_first_funding_year', 'age_last_funding_year', 'relationships',\n",
       "       'funding_rounds', 'funding_total_usd', 'milestones', 'is_CA', 'is_NY',\n",
       "       'is_MA', 'is_TX', 'is_otherstate', 'category_code', 'is_software',\n",
       "       'is_web', 'is_mobile', 'is_enterprise', 'is_advertising',\n",
       "       'is_gamesvideo', 'is_ecommerce', 'is_biotech', 'is_consulting',\n",
       "       'is_othercategory', 'object_id', 'has_VC', 'has_angel', 'has_roundA',\n",
       "       'has_roundB', 'has_roundC', 'has_roundD', 'avg_participants',\n",
       "       'is_top500'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eed9999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== Random Forest ===========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.69        65\n",
      "           1       0.82      0.88      0.85       120\n",
      "\n",
      "    accuracy                           0.80       185\n",
      "   macro avg       0.79      0.76      0.77       185\n",
      "weighted avg       0.80      0.80      0.80       185\n",
      "\n",
      "\n",
      "=========== Logistic Regression ===========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.20      0.30        65\n",
      "           1       0.68      0.93      0.78       120\n",
      "\n",
      "    accuracy                           0.67       185\n",
      "   macro avg       0.64      0.56      0.54       185\n",
      "weighted avg       0.65      0.67      0.61       185\n",
      "\n",
      "\n",
      "=========== SVM ===========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        65\n",
      "           1       0.65      1.00      0.79       120\n",
      "\n",
      "    accuracy                           0.65       185\n",
      "   macro avg       0.32      0.50      0.39       185\n",
      "weighted avg       0.42      0.65      0.51       185\n",
      "\n",
      "\n",
      "=========== Decision Tree ===========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.58      0.55        65\n",
      "           1       0.76      0.72      0.74       120\n",
      "\n",
      "    accuracy                           0.67       185\n",
      "   macro avg       0.64      0.65      0.65       185\n",
      "weighted avg       0.68      0.67      0.67       185\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Khoula\\OneDrive - Rihal\\Desktop\\startup-success-predictor\\backend\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Khoula\\OneDrive - Rihal\\Desktop\\startup-success-predictor\\backend\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Khoula\\OneDrive - Rihal\\Desktop\\startup-success-predictor\\backend\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Khoula\\OneDrive - Rihal\\Desktop\\startup-success-predictor\\backend\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "target_column = 'labels'\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object' or X[col].dtype.name == 'category':\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y,\n",
    ")\n",
    "\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"\\n=========== {name} ===========\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c878f9f7",
   "metadata": {},
   "source": [
    "# Preprocessing level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8add404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will test the models accuracy with minimal preprocessing\n",
    "# Dropping id columns and \n",
    "columns_to_drop = ['latitude', 'longitude', 'is_CA', 'is_NY',\n",
    "       'is_MA', 'is_TX', 'is_otherstate', 'is_software',\n",
    "       'is_web', 'is_mobile', 'is_enterprise', 'is_advertising',\n",
    "       'is_gamesvideo', 'is_ecommerce', 'is_biotech', 'is_consulting',\n",
    "       'is_othercategory', 'object_id',]\n",
    "df.drop(columns=columns_to_drop, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17985370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== Random Forest ===========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.65      0.70        65\n",
      "           1       0.82      0.89      0.86       120\n",
      "\n",
      "    accuracy                           0.81       185\n",
      "   macro avg       0.79      0.77      0.78       185\n",
      "weighted avg       0.80      0.81      0.80       185\n",
      "\n",
      "\n",
      "=========== Logistic Regression ===========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.40      0.46        65\n",
      "           1       0.71      0.81      0.76       120\n",
      "\n",
      "    accuracy                           0.66       185\n",
      "   macro avg       0.62      0.60      0.61       185\n",
      "weighted avg       0.65      0.66      0.65       185\n",
      "\n",
      "\n",
      "=========== SVM ===========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        65\n",
      "           1       0.65      1.00      0.79       120\n",
      "\n",
      "    accuracy                           0.65       185\n",
      "   macro avg       0.32      0.50      0.39       185\n",
      "weighted avg       0.42      0.65      0.51       185\n",
      "\n",
      "\n",
      "=========== Decision Tree ===========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.60      0.58        65\n",
      "           1       0.77      0.74      0.76       120\n",
      "\n",
      "    accuracy                           0.69       185\n",
      "   macro avg       0.67      0.67      0.67       185\n",
      "weighted avg       0.70      0.69      0.69       185\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Khoula\\OneDrive - Rihal\\Desktop\\startup-success-predictor\\backend\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Khoula\\OneDrive - Rihal\\Desktop\\startup-success-predictor\\backend\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Khoula\\OneDrive - Rihal\\Desktop\\startup-success-predictor\\backend\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Khoula\\OneDrive - Rihal\\Desktop\\startup-success-predictor\\backend\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "target_column = 'labels'\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object' or X[col].dtype.name == 'category':\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y,\n",
    ")\n",
    "\n",
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"\\n=========== {name} ===========\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ced74599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state_code', 'zip_code', 'city', 'name', 'labels', 'founded_at',\n",
       "       'first_funding_at', 'last_funding_at', 'age_first_funding_year',\n",
       "       'age_last_funding_year', 'relationships', 'funding_rounds',\n",
       "       'funding_total_usd', 'milestones', 'category_code', 'has_VC',\n",
       "       'has_angel', 'has_roundA', 'has_roundB', 'has_roundC', 'has_roundD',\n",
       "       'avg_participants', 'is_top500', 'has_RoundABCD', 'has_Investor',\n",
       "       'has_Seed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef91fd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========== Random Forest ===========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.60      0.67        65\n",
      "           1       0.81      0.90      0.85       120\n",
      "\n",
      "    accuracy                           0.79       185\n",
      "   macro avg       0.79      0.75      0.76       185\n",
      "weighted avg       0.79      0.79      0.79       185\n",
      "\n",
      "\n",
      "=========== Decision Tree ===========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.61        65\n",
      "           1       0.79      0.81      0.80       120\n",
      "\n",
      "    accuracy                           0.74       185\n",
      "   macro avg       0.71      0.70      0.71       185\n",
      "weighted avg       0.73      0.74      0.73       185\n",
      "\n",
      "\n",
      "=========== Logistic Regression ===========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.61        65\n",
      "           1       0.79      0.81      0.80       120\n",
      "\n",
      "    accuracy                           0.74       185\n",
      "   macro avg       0.71      0.70      0.71       185\n",
      "weighted avg       0.73      0.74      0.73       185\n",
      "\n",
      "\n",
      "=========== SVM ===========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.55      0.62        65\n",
      "           1       0.78      0.88      0.83       120\n",
      "\n",
      "    accuracy                           0.76       185\n",
      "   macro avg       0.74      0.71      0.72       185\n",
      "weighted avg       0.76      0.76      0.75       185\n",
      "\n",
      "\n",
      "=========== Neural Network (MLPClassifier) ===========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.59        65\n",
      "           1       0.78      0.76      0.77       120\n",
      "\n",
      "    accuracy                           0.70       185\n",
      "   macro avg       0.68      0.68      0.68       185\n",
      "weighted avg       0.71      0.70      0.70       185\n",
      "\n",
      "\n",
      "=========== XGBoost ===========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.66      0.69        65\n",
      "           1       0.82      0.86      0.84       120\n",
      "\n",
      "    accuracy                           0.79       185\n",
      "   macro avg       0.77      0.76      0.76       185\n",
      "weighted avg       0.79      0.79      0.79       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['has_RoundABCD'] = np.where((df['has_roundA'] == 1) | (df['has_roundB'] == 1) | (df['has_roundC'] == 1) | (df['has_roundD'] == 1), 1, 0)\n",
    "df['has_Investor'] = np.where((df['has_VC'] == 1) | (df['has_angel'] == 1), 1, 0)\n",
    "df['has_Seed'] = np.where((df['has_RoundABCD'] == 0) & (df['has_Investor'] == 1), 1, 0)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Split X, y\n",
    "# ------------------------------\n",
    "target_column = 'labels'\n",
    "X = df.drop(columns=[target_column, 'founded_at', 'name', 'has_roundA', 'has_roundB', 'has_roundC', 'has_VC',\n",
    "       'has_angel',], )\n",
    "y = df[target_column]\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. Identify categorical + numeric columns\n",
    "# -----------------------------------------------------\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. Preprocessing: OneHotEncode categorical + pass-through numeric\n",
    "# -----------------------------------------------------\n",
    "preprocess_no_scaling = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess_with_scaling = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. Classifiers (pipelines)\n",
    "# -----------------------------------------------------\n",
    "classifiers = {\n",
    "    \"Random Forest\": Pipeline([\n",
    "        (\"prep\", preprocess_no_scaling),\n",
    "        (\"clf\", RandomForestClassifier(max_depth= None, min_samples_split= 2))\n",
    "    ]),\n",
    "\n",
    "    \"Decision Tree\": Pipeline([\n",
    "        (\"prep\", preprocess_no_scaling),\n",
    "        (\"clf\", DecisionTreeClassifier())\n",
    "    ]),\n",
    "\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        (\"prep\", preprocess_with_scaling),\n",
    "        (\"clf\", LogisticRegression(max_iter=2000))\n",
    "    ]),\n",
    "\n",
    "    \"SVM\": Pipeline([\n",
    "        (\"prep\", preprocess_with_scaling),\n",
    "        (\"clf\", SVC())\n",
    "    ]),\n",
    "\n",
    "    \"Neural Network (MLPClassifier)\": Pipeline([\n",
    "        (\"prep\", preprocess_with_scaling),\n",
    "        (\"clf\", MLPClassifier(\n",
    "            hidden_layer_sizes=(64, 32),\n",
    "            activation=\"relu\",\n",
    "            solver=\"adam\",\n",
    "            max_iter=500,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ]),\n",
    "\n",
    "    \"XGBoost\": Pipeline([\n",
    "        (\"prep\", preprocess_no_scaling),\n",
    "        (\"clf\", XGBClassifier(\n",
    "            n_estimators=400,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            objective=\"binary:logistic\" if len(set(y)) == 2 else \"multi:softprob\",\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5. Train-test split\n",
    "# -----------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 6. Train & evaluate\n",
    "# -----------------------------------------------------\n",
    "for name, model in classifiers.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n=========== {name} ===========\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "806671e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/startup_data_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d74f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "startup-success-predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
